{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'size']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_message = []\n",
    "y_target = []\n",
    "with open(data_path, mode='r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        target, msg = line.split(',', maxsplit=1)\n",
    "        x_message.append(msg.lower())\n",
    "        y_target.append(target.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        self.category_priors = category_priors\n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "\n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = {}\n",
    "        self.sum_feature_counts = {}\n",
    "        \n",
    "        #Количество отдельных слов в статьях в данной категории\n",
    "        self.feature_category_article_counts = {}\n",
    "        self.sum_feature_category_article_counts = {}\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = {}\n",
    "        self.all_docs_count = 0\n",
    "        \n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = {}\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        for i in range(len(y_train)):            \n",
    "            if y_train[i] not in self.feature_category_counts:\n",
    "                self.feature_category_counts[y_train[i]] = {}\n",
    "                \n",
    "            if y_train[i] not in self.sum_feature_counts:\n",
    "                self.sum_feature_counts[y_train[i]] = 0\n",
    "                \n",
    "            if y_train[i] not in self.feature_category_article_counts:\n",
    "                self.feature_category_article_counts[y_train[i]] = {}\n",
    "            \n",
    "            if y_train[i] not in self.sum_feature_category_article_counts:\n",
    "                self.sum_feature_category_article_counts[y_train[i]] = 0\n",
    "            \n",
    "            if y_train[i] not in self.category_doc_counts:\n",
    "                self.category_doc_counts[y_train[i]] = 0                  \n",
    "                    \n",
    "            for line in x_train[i]:\n",
    "                self.all_docs_count += 1                \n",
    "                self.category_doc_counts[y_train[i]] += 1\n",
    "                line = line.split(' ')\n",
    "                \n",
    "                for word in set(line):\n",
    "                    if word not in self.feature_category_article_counts[y_train[i]]:\n",
    "                        self.feature_category_article_counts[y_train[i]][word] = 0\n",
    "                    if word not in self.feature_counts:\n",
    "                        self.feature_counts[word] = 0 \n",
    "                    self.feature_counts[word] += 1\n",
    "                    self.feature_category_article_counts[y_train[i]][word] += 1\n",
    "                    self.sum_feature_category_article_counts[y_train[i]] += 1\n",
    "                \n",
    "                for word in line:\n",
    "                    if word not in self.feature_category_counts[y_train[i]]:\n",
    "                        self.feature_category_counts[y_train[i]][word] = 0\n",
    "                    self.feature_category_counts[y_train[i]][word] += 1\n",
    "                    self.sum_feature_counts[y_train[i]] += 1\n",
    "                     \n",
    "        return self\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        categories = []\n",
    "        for line in text:\n",
    "            probs = self.get_probs(line)\n",
    "            categories.append(self.get_categories()[np.argmax(probs)])\n",
    "        return categories\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        return np.sum(np.array(self.predict(text)) == np.array(labels))/len(labels)\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        if not isinstance(text, list):\n",
    "            text= text.split(' ')\n",
    "        probs = []        \n",
    "        for category in self.category_doc_counts.keys():\n",
    "            probs.append(self.get_category_prob(category, text))\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятность принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        prob = 0\n",
    "        for word in text:\n",
    "            prob += math.log(self.get_weighted_feature_prob(cat, word))\n",
    "        prob += math.log(self.category_doc_counts[cat]/self.all_docs_count)\n",
    "\n",
    "        return prob\n",
    "    \n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        p_w_s = 0\n",
    "        total = 0\n",
    "        if feature in self.feature_counts:\n",
    "            total = self.feature_counts[feature]\n",
    "        if feature in self.feature_category_article_counts[cat]:\n",
    "            p_w_s = self.feature_category_article_counts[cat][feature]/self.sum_feature_category_article_counts[cat]\n",
    "        p_a_w = self.supposed_prob\n",
    "        if feature in self.feature_category_counts[cat]:\n",
    "            p_a_w = self.feature_category_counts[cat][feature]/self.sum_feature_counts[cat]\n",
    "        prob = (self.weight*p_a_w + total*p_w_s)/(total + self.weight) \n",
    "\n",
    "        return prob\n",
    "\n",
    "    def get_categories(self):\n",
    "        return list(self.category_doc_counts.keys())\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NaiveBayes at 0x7f750fd35d30>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = NaiveBayes()\n",
    "size = len(x_message)//2\n",
    "method.fit(x_message[:size], y_target[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7441217150760719\n"
     ]
    }
   ],
   "source": [
    "print(method.score(x_message[size + 1:], y_target[size + 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829302400631084"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "x_message = np.array(x_message)\n",
    "y_target = np.array(y_target)\n",
    "kf = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(x_message):\n",
    "    x_train_part, y_train_part = x_message[train_index], y_target[train_index]\n",
    "    x_test_part, y_test_part = x_message[test_index], y_target[test_index]\n",
    "    clf = NaiveBayes()\n",
    "    clf.fit(x_train_part, y_train_part)\n",
    "    accuracy.append(clf.score(x_test_part, y_test_part))\n",
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Предобработка данных для классификатора nltk, если требуется\n",
    "<your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "<your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<your code here>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
